{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from src.data_paths import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import igraph as ig\n",
    "\n",
    "\n",
    "### creates graph_data.pkl file which contains the nodes and edges of the graph\n",
    "class Graphdata_Creator:\n",
    "    def __init__(self, subfolder: str):\n",
    "        self.GRAPH_DATA_PATH = 'graph_data/' + subfolder + '/'\n",
    "        self.file_name = \"graph_data\"\n",
    "        self.df = pd.read_pickle(MERGED)\n",
    "        self.cosmic_protein = pd.read_csv(COSMIC_PROTEINS, sep='\\t')\n",
    "        self.all_prots_related_to_cancer_drugs = pd.DataFrame()\n",
    "        self.direct_effect_prots = pd.DataFrame()\n",
    "    \n",
    "    def create(self):\n",
    "        self.data_preprocessing()\n",
    "        self.create_graph_data()\n",
    "        self.save_igraph()\n",
    "\n",
    "    def data_preprocessing(self):\n",
    "        bind_cancer_proteins_by_name = self.df[self.df['drugbank_protein_name'].isin(self.cosmic_protein['Gene'])]\n",
    "        bind_cancer_proteins_by_uniprot = self.df[self.df['swissprot_protein_id'].isin(self.cosmic_protein['Uniprot'])]\n",
    "\n",
    "        most_studied_proteins = ['Cytochrome P450 3A4', 'Epidermal growth factor receptor', 'Proto-oncogene tyrosine-protein kinase Src', 'Vascular endothelial growth factor receptor 2', 'Adenosine receptor A2a', 'Cytochrome P450 2C9', 'Cytochrome P450 1A2', 'Cytochrome P450 2C19', 'Cytochrome P450 2D6', 'Prostaglandin G/H synthase 1', 'Prostaglandin G/H synthase 2']\n",
    "\n",
    "        # Add most studied proteins\n",
    "        bind_cancer_proteins_by_name = pd.concat([bind_cancer_proteins_by_name, self.df[self.df['target_name'].isin(most_studied_proteins)]])\n",
    "\n",
    "        self.cosmic_protein[self.cosmic_protein['Gene'] == 'EGFR'][['Gene', 'Gene synonym', 'Uniprot']]\n",
    "\n",
    "        cancer_related_proteins = pd.concat([bind_cancer_proteins_by_name, bind_cancer_proteins_by_uniprot]).drop_duplicates()\n",
    "        cancer_related_proteins_df = self.df[self.df['target_name'].isin(cancer_related_proteins['target_name'])]\n",
    "\n",
    "        ligands_related_to_cancer_proteins = cancer_related_proteins_df.dropna(subset=['ligand_name'])\n",
    "\n",
    "        drugs_related_to_cancer_proteins = ligands_related_to_cancer_proteins.dropna(subset='drugbank_drug_class_superclass')\n",
    "        all_prots_related_to_cancer_drugs = self.df[self.df['drugbank_drug_name'].isin(drugs_related_to_cancer_proteins['drugbank_drug_name'].unique())]\n",
    "\n",
    "        direct_prots_related_target_names = cancer_related_proteins['target_name'].unique()\n",
    "\n",
    "        direct_effect_prots = all_prots_related_to_cancer_drugs[all_prots_related_to_cancer_drugs['target_name'].isin(direct_prots_related_target_names)]\n",
    "\n",
    "        self.direct_effect_prots = direct_effect_prots\n",
    "        self.all_prots_related_to_cancer_drugs = all_prots_related_to_cancer_drugs\n",
    "\n",
    "    def _get_target_name_nonmutant(self, x):\n",
    "        return x.split('[')[0]\n",
    "    def create_graph_data(self):\n",
    "        self.df = pd.read_pickle(MERGED)\n",
    "\n",
    "        self.df['target_name_nonmutant'] = self.df['target_name'].apply(self._get_target_name_nonmutant)\n",
    "        self.df['target_name'].nunique(), self.df['target_name_nonmutant'].nunique()\n",
    "\n",
    "        unique_prots = self.df['target_name_nonmutant'].unique()\n",
    "\n",
    "        protein_to_doi = {prot: set() for prot in unique_prots}\n",
    "        for _, row in self.df.iterrows():\n",
    "            protein = row['target_name_nonmutant']\n",
    "            doi = row['doi']\n",
    "            protein_to_doi[protein].add(doi)\n",
    "\n",
    "\n",
    "        count = {prot: len(dois) for prot, dois in protein_to_doi.items()}\n",
    "        target_name_to_count = {row['target_name']: count[row['target_name_nonmutant']] for _, row in self.df.iterrows()}\n",
    "        # Create a list of nodes\n",
    "        nodes = []\n",
    "        node_id_map = {}  # To map node names to unique ids\n",
    "        categories = [{'name': 'Ligand'}, {'name': 'Protein'}]\n",
    "\n",
    "        # Process ligand nodes\n",
    "        ligand_nodes = self.df['ligand_name'].dropna().unique()\n",
    "        for idx, ligand in enumerate(ligand_nodes):\n",
    "            ligand = str(ligand)\n",
    "            node_id_map[ligand] = idx\n",
    "            node = {\n",
    "                'id': str(idx),\n",
    "                'Label': ligand,\n",
    "                'category': 0,  # Index of 'ligand' in categories\n",
    "                'research_count': np.median(list(target_name_to_count.values()))\n",
    "            }\n",
    "            nodes.append(node)\n",
    "\n",
    "        # Process protein nodes\n",
    "        protein_nodes = self.df['target_name'].dropna().unique()\n",
    "        for idx, protein in enumerate(protein_nodes, start=len(node_id_map)):\n",
    "            node_id_map[protein] = idx\n",
    "            node = {\n",
    "                'id': str(idx),\n",
    "                'Label': protein,\n",
    "                'category': 1,  # Index of 'protein' in categories\n",
    "                'research_count': target_name_to_count[protein]\n",
    "            }\n",
    "            nodes.append(node)\n",
    "\n",
    "        # Process edges efficiently\n",
    "        weights_ic = self.df['ic50'].values\n",
    "        weights_ec = self.df['ec50'].values\n",
    "        weights = np.where(pd.isna(weights_ic), weights_ec, weights_ic)\n",
    "\n",
    "        weights = np.log(np.log(weights))\n",
    "        max_strength = np.quantile(weights[~np.isnan(weights)], 0.95)\n",
    "        min_strength = np.quantile(weights[~np.isnan(weights)], 0.05)\n",
    "        weights = (weights - min_strength) / (max_strength - min_strength)\n",
    "        weights = np.where(np.isnan(weights), 0, weights)\n",
    "        weights = np.where(weights < 0.1, pd.NA, weights)\n",
    "\n",
    "        # Edges is df[['ligand_name', 'traget_name', weights]] where weights is not nan\n",
    "        # Don't use loop\n",
    "        edges = self.df[['ligand_name', 'target_name']].copy()\n",
    "        edges['source'] = edges['ligand_name'].map(node_id_map)\n",
    "        edges['target'] = edges['target_name'].map(node_id_map)\n",
    "        edges['sourceLabel'] = edges['ligand_name']\n",
    "        edges['targetLabel'] = edges['target_name']\n",
    "        edges['Weight'] = weights\n",
    "        edges = edges.dropna(subset=['source', 'target', 'Weight'])\n",
    "        edges['Weight'] = edges['Weight'].clip(0.1, 1)\n",
    "\n",
    "        edges = edges.to_dict(orient='records')\n",
    "\n",
    "        # Create the graph data\n",
    "        graph_data = {\n",
    "            'nodes': nodes,\n",
    "            'links': edges,\n",
    "            'categories': categories\n",
    "        }\n",
    "        \n",
    "        self.graph_data = graph_data\n",
    "    \n",
    "    def save_igraph(self):\n",
    "                # Extract node and edge data\n",
    "        nodes = self.graph_data['nodes']\n",
    "        edges = self.graph_data['links']\n",
    "        categories = self.graph_data['categories']\n",
    "\n",
    "        # Create an igraph graph\n",
    "        g = ig.Graph(directed=False)  # Set directed=True if your data is directional\n",
    "        g.add_vertices(len(nodes))\n",
    "\n",
    "        # Add vertex attributes\n",
    "        for i, node in enumerate(nodes):\n",
    "            g.vs[i]['name'] = node['Label']\n",
    "            g.vs[i]['category'] = categories[node['category']]['name']\n",
    "            g.vs[i]['research_count'] = node['research_count']\n",
    "            g.vs[i]['type'] = (node['category'] == 'Ligand')\n",
    "\n",
    "        # Add edges\n",
    "        edge_list = [(int(e['source']), int(e['target'])) for e in edges]\n",
    "        g.add_edges(edge_list)\n",
    "\n",
    "        # # Add edge attributes\n",
    "        if 'Weight' in edges[0]:\n",
    "            for i, e in enumerate(edges):\n",
    "                g.es[i]['affinity'] = e['Weight']\n",
    "                g.es[i]['sourceLabel'] = e['sourceLabel']\n",
    "                g.es[i]['targetLabel'] = e['targetLabel']\n",
    "\n",
    "\n",
    "        # # g = g.subgraph_edges(g.es.select(affinity_gt=0), delete_vertices=True)\n",
    "\n",
    "        # # Recompute nodes and edges\n",
    "        nodes = []\n",
    "        edges = []\n",
    "\n",
    "        for i, v in enumerate(g.vs):\n",
    "            nodes.append({\n",
    "                'id': i,\n",
    "                'Label': v['name'],\n",
    "                'category': v['category'],\n",
    "                'type': v['type'],\n",
    "                'research_count': v['research_count']\n",
    "            })\n",
    "\n",
    "        for e in g.es:\n",
    "            edges.append({\n",
    "                'source': e.source,\n",
    "                'target': e.target,\n",
    "                'Weight': e['affinity'],\n",
    "                'sourceLabel': e['sourceLabel'],\n",
    "                'targetLabel': e['targetLabel']\n",
    "            })\n",
    "            ### Save graph_data to pickle\n",
    "        if not os.path.exists(self.GRAPH_DATA_PATH):\n",
    "            os.makedirs(self.GRAPH_DATA_PATH)\n",
    "        \n",
    "        all_nodes_df = pd.DataFrame(nodes)\n",
    "        all_edges_df = pd.DataFrame(edges)\n",
    "\n",
    "        all_nodes_df.to_csv(self.GRAPH_DATA_PATH + 'all_nodes.csv', index=False)\n",
    "        all_edges_df.to_csv(self.GRAPH_DATA_PATH + 'all_edges.csv', index=False)\n",
    "        with open(self.GRAPH_DATA +'igraph_object.pkl', 'wb') as f:\n",
    "            pickle.dump(g, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graphdata_Creator(\"all\").create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyecharts.charts import Graph\n",
    "from pyecharts import options as opts\n",
    "class Graph_Visualizer():\n",
    "    def __init__(self, subfolder:str):\n",
    "        self.GRAPH_DATA_PATH = 'graph_data/' + subfolder + '/'\n",
    "        self.file_name = \"graph_data\"\n",
    "        self.igraph_object = None\n",
    "    \n",
    "    def get_igraph_object(self):\n",
    "        with open(self.GRAPH_DATA_PATH + 'igraph_object.pkl', 'rb') as f:\n",
    "            self.igraph_object = pickle.load(f)\n",
    "        if self.igraph_object is None:\n",
    "            raise Exception(\"No igraph object found\")\n",
    "    \n",
    "    def render_html(self, project_on: str):\n",
    "        proj_nodes, proj_edges = self._bipartite_projection_with_affinity(self.igraph_object, project_on=project_on)\n",
    "        graph = self._generate_echarts_graph(proj_nodes, proj_edges)\n",
    "        graph.set_global_opts(\n",
    "            title_opts=opts.TitleOpts(title=\"Cancer Drugs Projected Interaction Network\")\n",
    "        )\n",
    "        graph.render(self.GRAPH_DATA_PATH +f\"cancer_{project_on}_graph.html\")\n",
    "\n",
    "    def visualize(self):\n",
    "        self.get_igraph_object()\n",
    "        self.render_html(\"ligand\")\n",
    "        self.render_html(\"protein\")\n",
    "    \n",
    "    def _bipartite_projection_with_affinity(g, project_on=\"ligand\"):\n",
    "        \"\"\"\n",
    "        Compute a bipartite projection of the given graph `g` onto either the ligand or protein side.\n",
    "        Then, aggregate 'affinity' values for each projected edge.\n",
    "\n",
    "        Parameters:\n",
    "        g : igraph.Graph\n",
    "            The original bipartite graph with\n",
    "            - `g.es['affinity']` set on the bipartite edges\n",
    "        project_on : str, optional, default: 'ligand'\n",
    "            Which set of nodes to project on. \n",
    "            'ligand' projects onto ligand nodes (type=True),\n",
    "            'protein' projects onto protein nodes (type=False).\n",
    "\n",
    "        Returns:\n",
    "        proj_nodes : list of dict\n",
    "            A list of node dictionaries with 'id' and 'name'.\n",
    "        proj_edges : list of dict\n",
    "            A list of edge dictionaries with 'source', 'target', and aggregated 'affinity'.\n",
    "        \"\"\"\n",
    "\n",
    "        # Perform bipartite projection\n",
    "        # g_ligand_proj: projection onto ligand nodes\n",
    "        # g_protein_proj: projection onto protein nodes\n",
    "        g_ligand_proj, g_protein_proj = g.bipartite_projection(multiplicity=True)\n",
    "\n",
    "        # Choose which projection to work with\n",
    "        if project_on == \"ligand\":\n",
    "            g_proj = g_ligand_proj\n",
    "        elif project_on == \"protein\":\n",
    "            g_proj = g_protein_proj\n",
    "        else:\n",
    "            raise ValueError(\"project_on must be either 'ligand' or 'protein'\")\n",
    "\n",
    "        # Create lookup from node name to original index for convenience\n",
    "        name_to_index = {v['name']: v.index for v in g.vs}\n",
    "\n",
    "        # Compute aggregated affinity on projected edges\n",
    "        for e in g_proj.es:\n",
    "            source_name = g_proj.vs[e.source]['name']\n",
    "            target_name = g_proj.vs[e.target]['name']\n",
    "\n",
    "            # Map back to original graph indices\n",
    "            source_index = name_to_index[source_name]\n",
    "            target_index = name_to_index[target_name]\n",
    "\n",
    "            # Find common neighbors in original graph\n",
    "            source_neighbors = set(g.neighbors(source_index))\n",
    "            target_neighbors = set(g.neighbors(target_index))\n",
    "            shared_intermediates = source_neighbors & target_neighbors\n",
    "\n",
    "            # We do the average of the affinities\n",
    "            affinities = []\n",
    "            for p in shared_intermediates:\n",
    "                eid_source_p = g.get_eid(source_index, p)\n",
    "                eid_target_p = g.get_eid(target_index, p)\n",
    "\n",
    "                aff_source_p = g.es[eid_source_p]['affinity']\n",
    "                aff_target_p = g.es[eid_target_p]['affinity']\n",
    "\n",
    "                avg_aff = (aff_source_p + aff_target_p) / 2.0\n",
    "                affinities.append(avg_aff)\n",
    "\n",
    "            e['affinity'] = sum(affinities)/len(affinities) if affinities else None\n",
    "\n",
    "        # Retrieve nodes with their names\n",
    "        proj_nodes = []\n",
    "        for v in g_proj.vs:\n",
    "            proj_nodes.append({\n",
    "                'id': v.index,\n",
    "                'name': v['name']\n",
    "            })\n",
    "\n",
    "        # Retrieve edges with their aggregated affinity\n",
    "        proj_edges = []\n",
    "        for e in g_proj.es:\n",
    "            proj_edges.append({\n",
    "                'source': e.source,\n",
    "                'target': e.target,\n",
    "                'affinity': e['affinity']\n",
    "            })\n",
    "\n",
    "        return proj_nodes, proj_edges\n",
    "\n",
    "    \n",
    "\n",
    "def _generate_echarts_graph(nodes, edges):\n",
    "    \"\"\"\n",
    "    Generate an ECharts graph from the given nodes and edges.\n",
    "\n",
    "    Parameters:\n",
    "    nodes : list of dict\n",
    "        A list of node dictionaries with 'id', 'name', and 'symbolSize'.\n",
    "    edges : list of dict\n",
    "        A list of edge dictionaries with 'source', 'target', and 'lineStyle'.\n",
    "\n",
    "    Returns:\n",
    "    graph : pyecharts.charts.Graph\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute node degrees\n",
    "    node_degrees = {node[\"id\"]: 0 for node in nodes}\n",
    "    for edge in edges:\n",
    "        node_degrees[edge[\"source\"]] += 1\n",
    "        node_degrees[edge[\"target\"]] += 1\n",
    "\n",
    "    # Assign symbol_size to each node based on its degree\n",
    "    for node in nodes:\n",
    "        degree = node_degrees[node[\"id\"]]\n",
    "        # For example, make the size proportional to degree * 5, fallback to 10 if degree = 0\n",
    "        node[\"symbolSize\"] = np.clip(degree, 0.1, 10) if degree > 0 else 0.1\n",
    "\n",
    "    # Assign edge width based on 'affinity' (if available)\n",
    "    for edge in edges:\n",
    "        weight = edge.get(\"affinity\", 0.5) * 3\n",
    "        edge[\"lineStyle\"] = {\"width\": weight}  # scale it up if needed\n",
    "\n",
    "    # Create the graph\n",
    "    graph = Graph(init_opts=opts.InitOpts(width=\"100%\", height=\"700px\"))\n",
    "    graph.add(\n",
    "        series_name=\"\",\n",
    "        nodes=nodes,\n",
    "        links=edges,\n",
    "        layout=\"force\",\n",
    "        edge_length=[100, 250],\n",
    "        repulsion=200,\n",
    "        linestyle_opts=opts.LineStyleOpts(opacity=0.5)  # Base line style\n",
    "\n",
    "    )\n",
    "\n",
    "    graph.set_series_opts(\n",
    "        label_opts=opts.LabelOpts(\n",
    "            is_show=False,  # Hide labels by default\n",
    "            position=\"right\",\n",
    "            formatter=\"{b}\"  # Use node name as the label\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph_Visualizer(\"all\").visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
